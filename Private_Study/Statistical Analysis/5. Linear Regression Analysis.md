
> ##### 2023년 6월 3일 토요일 ADP 실기 시험을 위한 공부(5/16~6/2)
##### 🔥 기본적인 데이터 전처리 및 머신러닝 파트는 주피터 노트북을 이용하여 공부하고 [깃허브](https://github.com/DMIS0126/ADP/tree/main/Private_Study)에 정리 완료
##### 🔥 통계분석은 이론 정리가 되어야 코드를 제대로 적을 수 있을 것 같다고 판단하여 블로그에 정리 시작

---

## ✐ 지금까지 배운 내용 정리
* 머신러닝은 예측의 성공 확률을 높이는 데에 목적이 있다면, 
* 전통적 통계분석 방법은 정해진 분포나 가정을 통해 실패 확률을 줄이고 원인을 찾는 데에 목적이 있다.
* 이미 머신러닝 파트에서 선형 회귀, 다항 회귀를 학습하였으므로 이 절에서는 전통적 통계기법을 사용한 회귀분석이 머신러닝보다 설명력이 좋은지를 비교해보고자 한다.

  > 🗒 지금까지 배운 분석들을 각각 언제 사용하는지 표로 정리
  >
  > <table border = "1">
    <td rowspan = "2", colspan="2">구분</td>
    <td colspan="2">독립변수</td>
    <tr>
      <td >범주형</td>
    <td>연속형</td>
      <tr>
  <td rowspan = "2">종속변수</td>
    <td>범주형</td>
    <td>교차분석</td>
    <td>로지스틱 회귀분석(분류분석)</td>
          <tr>
  <td>연속형</td>
    <td>t-test, ANOVA</td>
    <td>회귀분석</td>
              <tr>
    </table>


  > * ADP 문제를 풀 때 가장 먼저 확인해야 하는 것은 데이터의 타입이다.
  > 
  > * 데이터의 타입에 따라 분석기법이 달라지며, 종속변수와 독립변수가 모두 연속형일 때는 주로 회귀분석을 사용한다.


---

## ✐ 회귀분석

### ⚑ 개념
* 회귀분석은 머신러닝과 다르게 식으로 표현하므로 해석력을 높일 수 있다.
* 또한, 변수들 사이의 상관관계를 밝히고 모형을 적합하여 관심있는 변수를 예측하거나 추론하기 위해 사용한다.
* 독립변수의 개수가 하나일 때, 단순 선형 회귀분석이라 하며, 독립변수가의 개수가 두 개 이상이면 다중 선형 회귀분석이라 한다.

### ⚑ 분석에 대한 평가
1. 단순 선형 회귀분석
  * 머신러닝의 회귀분석과 마찬가지로 잔차의 합이 최소가 되는 최소제곱법을 사용한다.
    * 즉, 하나의 선이 전체 데이터를 얼마나 잘 설명할 수 있는지가 회귀분석의 평가지표가 된다.
  * 주로 사용하는 평가지표는 $R^{2}$(결정계수)와 RMSE이다.
  > 💡 $R^{2}$(결정계수)
  >
  > 결정계수를 이해하기 위해 필요한 것
  > 
  > * SST(total sum of squares)(총변동) : 개별 y의 편차 제곱의 합
  >   * $SST = \displaystyle \sum_{i=1}^n(y_i-\overline{y})^{2}$
  > 
  > * SSE(explained sum of squares)(설명된 변동) : 회귀식 추정 y의 편차 제곱의 합
  >   * $SSE = \displaystyle \sum_{i=1}^n(\hat{y}_i-\overline{y})^{2}$
  > 
  > * SSR(residual sum of squares)(설명되지 않은 변동) : 잔차(residual = $y_i-\hat{y}_i$)의 제곱의 합
  >   * $SSR = \displaystyle \sum_{i=1}^n(y_i-\hat{y})^{2}$
  > 
  > $\therefore SST = SSE+SSR$
  > 
  > 이때, $R^{2}$을 다음과 같이 정의한다.
  > 
  > $R^{2}=1-\dfrac{SSR}{SST}$
  >  * 총 변동 중 설명된 변동의 비율
  >
  > * 즉, $R^{2}$은 <span style="color:#7FFFD4;">회귀 추정선이 전체 데이터를 얼마나 잘 설명하고 있는가</span>를 의미하므로 값이 높다면, 구한 <span style="color:#7FFFD4;">회귀 추정 직선으로 새로운 값을 예측하거나 추정하여도 믿을 만하다</span>는 것을 의미한다.

  > 💡 RMSE(Root Mean Square Error)(평균 제곱근 오차)
  > 
  > $RMSE = \sqrt{\displaystyle\sum_{i=1}^{n}\dfrac{(\hat{y}_i-y_i)^{2}}{n-2}}$
  >  * $n-2$ : 자유도
  >
  > * RMSE 또한 선형 모델이 예측한 값과 실제 관측값의 차이를 의미한다는 개념이 중요하다.
  > 
  > * 모델의 성능을 테스트해봤을 때, 이 값이 작다면 예측을 잘했다고 할 수 있다.
  
  
2. 다중 선형 회귀분석
* 다중 선형 회귀분석은 독립변수의 개수가 2 이상일 때 사용하는데, 독립변수의 개수가 늘어나면 모델의 $R^{2}$이 증가하게 된다.
* 이에 따라 모델의 성능이 독립변수의 개수에 따라 증가하는 것에 대한 패널티를 적용시킨다.
  $AdjustedR^{2}=\displaystyle1-\dfrac{SSR\div(n-k-1)}{SST\div(n-1)}$
  > 💡 n이 커진다면 1, 2들의 값의 차이는 큰 의미가 없어 자유도로 나누지 않고 n으로 나눈다.
  > 
  >   sklearn.metirics에 있는 mean_square_error도 n으로 나눈 값이다.
  
### ⚑ 회귀분석 검토사항
1. 모델이 데이터를 잘 적합하고 있는가?
   * 모형의 잔차(residual= $y_i-\hat{y}_i$)가 특정 패턴을 이루고 있지 않아야 한다.
   ![](https://cdn.teamturing.com/cms/1684451284_residual.png)
2. 회귀 모형이 통계적으로 유의한가?
   * 선형 회귀 모형의 통계량은 F 통계량을 사용한다. F 통계량의 p-value가 유의수준보다 작으면 회귀식이 통계적으로 유의하다고 볼 수 있다. 이때의 귀무가설과 대립가설은 다음과 같다.
     * 귀무가설(H0) : 회귀 모형은 유의하지 않다.
     * 대립가설(H1) : 회귀 모형은 유의하다.
3. 모형은 데이터를 얼마나 설명할 수 있는가?
   * $R^{2}$의 값을 확인한다. $R^{2}$은 비율이기에 0~1의 값을 가지며, 추정된 회귀식이 전체 데이터에서 설명할 수 있는 데이터의 비율이다.
4. 모형 내의 회귀계수는 유의한가?
   * 회귀계수에 대해서는 각 독립변수를 검정해야 한다.
   * 회귀계수에 대한 통계량은 t값이며, p-value가 유의수준보다 작으면 회귀계수가 통계적으로 유의하다고 할 수 있다.



