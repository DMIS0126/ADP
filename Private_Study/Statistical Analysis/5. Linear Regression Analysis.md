# ë°‘ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” í†µê³„ë¶„ì„ (5) ì„ í˜• íšŒê·€ë¶„ì„


> ##### 2023ë…„ 6ì›” 3ì¼ í† ìš”ì¼ ADP ì‹¤ê¸° ì‹œí—˜ì„ ìœ„í•œ ê³µë¶€(5/16~6/2)
##### ğŸ”¥ ê¸°ë³¸ì ì¸ ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¨¸ì‹ ëŸ¬ë‹ íŒŒíŠ¸ëŠ” ì£¼í”¼í„° ë…¸íŠ¸ë¶ì„ ì´ìš©í•˜ì—¬ ê³µë¶€í•˜ê³  [ê¹ƒí—ˆë¸Œ](https://github.com/DMIS0126/ADP/tree/main/Private_Study)ì— ì •ë¦¬ ì™„ë£Œ
##### ğŸ”¥ í†µê³„ë¶„ì„ì€ ì´ë¡  ì •ë¦¬ê°€ ë˜ì–´ì•¼ ì½”ë“œë¥¼ ì œëŒ€ë¡œ ì ì„ ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤ê³  íŒë‹¨í•˜ì—¬ ë¸”ë¡œê·¸ì— ì •ë¦¬ ì‹œì‘

---

## âœ ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ë‚´ìš© ì •ë¦¬
* ë¨¸ì‹ ëŸ¬ë‹ì€ ì˜ˆì¸¡ì˜ ì„±ê³µ í™•ë¥ ì„ ë†’ì´ëŠ” ë°ì— ëª©ì ì´ ìˆë‹¤ë©´, 
* ì „í†µì  í†µê³„ë¶„ì„ ë°©ë²•ì€ ì •í•´ì§„ ë¶„í¬ë‚˜ ê°€ì •ì„ í†µí•´ ì‹¤íŒ¨ í™•ë¥ ì„ ì¤„ì´ê³  ì›ì¸ì„ ì°¾ëŠ” ë°ì— ëª©ì ì´ ìˆë‹¤.
* ì´ë¯¸ ë¨¸ì‹ ëŸ¬ë‹ íŒŒíŠ¸ì—ì„œ ì„ í˜• íšŒê·€, ë‹¤í•­ íšŒê·€ë¥¼ í•™ìŠµí•˜ì˜€ìœ¼ë¯€ë¡œ ì´ ì ˆì—ì„œëŠ” ì „í†µì  í†µê³„ê¸°ë²•ì„ ì‚¬ìš©í•œ íšŒê·€ë¶„ì„ì´ ë¨¸ì‹ ëŸ¬ë‹ë³´ë‹¤ ì„¤ëª…ë ¥ì´ ì¢‹ì€ì§€ë¥¼ ë¹„êµí•´ë³´ê³ ì í•œë‹¤.

   ğŸ—’ ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ë¶„ì„ë“¤ì„ ê°ê° ì–¸ì œ ì‚¬ìš©í•˜ëŠ”ì§€ í‘œë¡œ ì •ë¦¬
  ![](https://velog.velcdn.com/images/dmis/post/a26bbdce-68a5-4d10-adfd-fff2097e487b/image.png)

  > * ADP ë¬¸ì œë¥¼ í’€ ë•Œ ê°€ì¥ ë¨¼ì € í™•ì¸í•´ì•¼ í•˜ëŠ” ê²ƒì€ ë°ì´í„°ì˜ íƒ€ì…ì´ë‹¤.
	  > 
  > * ë°ì´í„°ì˜ íƒ€ì…ì— ë”°ë¼ ë¶„ì„ê¸°ë²•ì´ ë‹¬ë¼ì§€ë©°, ì¢…ì†ë³€ìˆ˜ì™€ ë…ë¦½ë³€ìˆ˜ê°€ ëª¨ë‘ ì—°ì†í˜•ì¼ ë•ŒëŠ” ì£¼ë¡œ íšŒê·€ë¶„ì„ì„ ì‚¬ìš©í•œë‹¤.


---

## âœ íšŒê·€ë¶„ì„

### âš‘ ê°œë…
* íšŒê·€ë¶„ì„ì€ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë‹¤ë¥´ê²Œ ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë¯€ë¡œ í•´ì„ë ¥ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.
* ë˜í•œ, ë³€ìˆ˜ë“¤ ì‚¬ì´ì˜ ìƒê´€ê´€ê³„ë¥¼ ë°íˆê³  ëª¨í˜•ì„ ì í•©í•˜ì—¬ ê´€ì‹¬ìˆëŠ” ë³€ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê±°ë‚˜ ì¶”ë¡ í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•œë‹¤.
* ë…ë¦½ë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ í•˜ë‚˜ì¼ ë•Œ, ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¶„ì„ì´ë¼ í•˜ë©°, ë…ë¦½ë³€ìˆ˜ê°€ì˜ ê°œìˆ˜ê°€ ë‘ ê°œ ì´ìƒì´ë©´ ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„ì´ë¼ í•œë‹¤.

### âš‘ ë¶„ì„ì— ëŒ€í•œ í‰ê°€
#### 1. ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¶„ì„
  * ë¨¸ì‹ ëŸ¬ë‹ì˜ íšŒê·€ë¶„ì„ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ì”ì°¨ì˜ í•©ì´ ìµœì†Œê°€ ë˜ëŠ” ìµœì†Œì œê³±ë²•ì„ ì‚¬ìš©í•œë‹¤.
    * ì¦‰, í•˜ë‚˜ì˜ ì„ ì´ ì „ì²´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ì§€ê°€ íšŒê·€ë¶„ì„ì˜ í‰ê°€ì§€í‘œê°€ ëœë‹¤.
  * ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” í‰ê°€ì§€í‘œëŠ” $R^{2}$(ê²°ì •ê³„ìˆ˜)ì™€ RMSEì´ë‹¤.
  > ğŸ’¡ $R^{2}$(ê²°ì •ê³„ìˆ˜)
  >
  > ê²°ì •ê³„ìˆ˜ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ê²ƒ
  > 
  > * SST(total sum of squares)(ì´ë³€ë™) : ê°œë³„ yì˜ í¸ì°¨ ì œê³±ì˜ í•©
  >   * $SST = \displaystyle \sum_{i=1}^n(y_i-\overline{y})^{2}$
  > 
  > * SSE(explained sum of squares)(ì„¤ëª…ëœ ë³€ë™) : íšŒê·€ì‹ ì¶”ì • yì˜ í¸ì°¨ ì œê³±ì˜ í•©
  >   * $SSE = \displaystyle \sum_{i=1}^n(\hat{y}_i-\overline{y})^{2}$
  > 
  > * SSR(residual sum of squares)(ì„¤ëª…ë˜ì§€ ì•Šì€ ë³€ë™) : ì”ì°¨(residual = $y_i-\hat{y}_i$)ì˜ ì œê³±ì˜ í•©
  >   * $SSR = \displaystyle \sum_{i=1}^n(y_i-\hat{y})^{2}$
  > 
  > $\therefore SST = SSE+SSR$
  > 
  > ì´ë•Œ, $R^{2}$ì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•œë‹¤.
  > 
  > $R^{2}=1-\dfrac{SSR}{SST}$
  >  * ì´ ë³€ë™ ì¤‘ ì„¤ëª…ëœ ë³€ë™ì˜ ë¹„ìœ¨
  >
  > * ì¦‰, $R^{2}$ì€ <span style="color:#7FFFD4;">íšŒê·€ ì¶”ì •ì„ ì´ ì „ì²´ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ê³  ìˆëŠ”ê°€</span>ë¥¼ ì˜ë¯¸í•˜ë¯€ë¡œ ê°’ì´ ë†’ë‹¤ë©´, êµ¬í•œ <span style="color:#7FFFD4;">íšŒê·€ ì¶”ì • ì§ì„ ìœ¼ë¡œ ìƒˆë¡œìš´ ê°’ì„ ì˜ˆì¸¡í•˜ê±°ë‚˜ ì¶”ì •í•˜ì—¬ë„ ë¯¿ì„ ë§Œí•˜ë‹¤</span>ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

  > ğŸ’¡ RMSE(Root Mean Square Error)(í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)
  > 
  > $RMSE = \sqrt{\displaystyle\sum_{i=1}^{n}\dfrac{(\hat{y}_i-y_i)^{2}}{n-2}}$
  >  * $n-2$ : ììœ ë„
  >
  > * RMSE ë˜í•œ ì„ í˜• ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°’ê³¼ ì‹¤ì œ ê´€ì¸¡ê°’ì˜ ì°¨ì´ë¥¼ ì˜ë¯¸í•œë‹¤ëŠ” ê°œë…ì´ ì¤‘ìš”í•˜ë‹¤.
  > 
  > * ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•´ë´¤ì„ ë•Œ, ì´ ê°’ì´ ì‘ë‹¤ë©´ ì˜ˆì¸¡ì„ ì˜í–ˆë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.
  
#### ğŸ§‘â€ğŸ’» ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¶„ì„ ì‹¤ìŠµ
```python
# kc_house_dataì˜ sqft_livingì„ ë…ë¦½ë³€ìˆ˜, priceë¥¼ ì¢…ì†ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì—¬ ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¶„ì„ í•´ë³´ê³ , ê²°ê³¼ í•´ì„í•˜ê¸°
import pandas as pd
house = pd.read_csv('./data/kc_house_data.csv')
house = house[['sqft_living', 'price']]
house.corr()

from statsmodels.formula.api import ols # OLS: Ordinary Least Squares
import matplotlib.pyplot as plt

x = house['sqft_living']
y = house['price']

lr = ols('price ~ sqft_living', data = house).fit()
y_pred = lr.predict(x)

plt.scatter(x, y)
plt.plot(x, y_pred, color = 'red') # íšŒê·€ì§ì„  ì¶”ê°€
plt.xlabel('sqft_living')
plt.ylabel('price')
plt.title('Linear Regression Result')
plt.show()
```
![](https://velog.velcdn.com/images/dmis/post/6fd0a41d-aa63-432e-8162-664685561791/image.png)
> ğŸ‘€  **ìœ„ì˜ ì°¨íŠ¸ë¥¼ í†µí•œ <span style="color:#7FFFD4;">ëª¨í˜•ì´ ë°ì´í„°ë¥¼ ì˜ ì í•©í•˜ê³  ìˆëŠ”ê°€?</span>ì— ëŒ€í•œ í•´ì„ **
> 
> * ì‹œê°í™” ê²°ê³¼ ì§ê´€ì ìœ¼ë¡œë„ ì§ì„ ì´ ëª¨ë“  ë°ì´í„°ë¥¼ ì˜ ì„¤ëª…í•˜ì§€ëŠ” ëª»í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.
> 
> * ë˜í•œ, (0, 0)ì—ì„œ ë©€ì–´ì§ˆìˆ˜ë¡ ì˜¤ì°¨ì˜ ë¶„ì‚°ì´ ì»¤ì§€ëŠ” íŠ¹ì •í•œ íŒ¨í„´ì„ ì´ë£¨ê³  ìˆìœ¼ë¯€ë¡œ ë‹¨ìˆœ íšŒê·€ë¶„ì„ìœ¼ë¡œëŠ” ë°ì´í„°ë¥¼ ì¶©ë¶„íˆ ì„¤ëª…í•  ìˆ˜ ì—†ëŠ” ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.

``` python
# ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¶„ì„ì˜ ìš”ì•½ ì •ë³´ í™•ì¸
lr.summary()
```
![](https://velog.velcdn.com/images/dmis/post/a48c7c3d-e14a-4e0f-a3d4-e38950e4b388/image.png)

> ğŸ‘€ ** ìœ„ì˜ ìš”ì•½ ì •ë³´ì— ëŒ€í•œ í•´ì„** 
>
> **<span style="color:#7FFFD4;">1. íšŒê·€ ëª¨í˜•ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œê°€?</span>**
> * ê·€ë¬´ê°€ì„¤ : íšŒê·€ ëª¨í˜•ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•Šë‹¤.
> * ëŒ€ë¦½ê°€ì„¤ : íšŒê·€ ëª¨í˜•ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ë‹¤.
> * ìœ„ì˜ ìš”ì•½ ì •ë³´ì—ì„œ Fí†µê³„ëŸ‰ê³¼ p-valueì¸ Prob(F-statistic)ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ”ë°, p-valueê°€ 0ì´ë¯€ë¡œ ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì— ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì—¬ ëŒ€ë¦½ê°€ì„¤ì„ ì±„íƒí•œë‹¤.
>   * ì¦‰, íšŒê·€ ëª¨í˜•ì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ë‹¤.
> ---
> **<span style="color:#7FFFD4;">2. ëª¨í˜•ì€ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?</span>**
>  $R^{2}=0.493$ìœ¼ë¡œ ì´ ëª¨í˜•ì´ ì „ì²´ ë°ì´í„°ì˜ 49.3%ë¥¼ ì„¤ëª…í•œë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.
> * ğŸ’¡ í†µê³„ ëª¨ë¸ì´ ìœ ì˜í•˜ë‹¤ê³  í•˜ì—¬, ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ì€ ê²ƒì€ ì•„ë‹ˆë‹¤.
>   * í•˜ì§€ë§Œ, $R^{2}=0.493$ì¸ ê²ƒì´ ì‚°ì—…ì— ë”°ë¼ì„œëŠ” ì—„ì²­ë‚œ ì •í™•ë„ë¥¼ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¬í•  ìˆ˜ë„ ìˆë‹¤.
> 
> ---
> **<span style="color:#7FFFD4;">3. ëª¨í˜• ë‚´ì˜ íšŒê·€ ê³„ìˆ˜ëŠ” ìœ ì˜í•œê°€?</span>**
> * interceptëŠ” ëª¨í˜•ì˜ ìƒìˆ˜ê°’ì´ë¯€ë¡œ ê´€ì‹¬ì‚¬ê°€ ì•„ë‹ˆë‹¤.
> * ë³€ìˆ˜ì¸ sqft_livingì˜ íšŒê·€ê³„ìˆ˜ì— ëŒ€í•œ p-valueì¸ P>|t|ë¥¼ ë³´ë©´, 0ì´ë¯€ë¡œ ìœ ì˜ìˆ˜ì¤€ 0.05 í•˜ì— ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì—¬ ëŒ€ë¦½ê°€ì„¤ì„ ì±„íƒí•œë‹¤.
>   * ì¦‰, sqft_livingì€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ë¡œ ë³¼ ìˆ˜ ìˆë‹¤.
> 
> ---
>  ìœ„ì˜ ê²°ê³¼ë¥¼ ëª¨ë‘ ì¢…í•©í•˜ì—¬, ì „ì²´ ë°ì´í„°ì˜ 49.3%ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ë‹¤ìŒê³¼ ê°™ì€ íšŒê·€ì‹ì„ ë„ì¶œí•  ìˆ˜ ìˆë‹¤.
> * ${Price} = {sqft\_livng} \times 280.6236 + (-43580.743094)$
 
--- 
 
 
#### 2. ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„
* ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„ì€ ë…ë¦½ë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ 2 ì´ìƒì¼ ë•Œ ì‚¬ìš©í•˜ëŠ”ë°, ë…ë¦½ë³€ìˆ˜ì˜ ê°œìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë©´ ëª¨ë¸ì˜ $R^{2}$ì´ ì¦ê°€í•˜ê²Œ ëœë‹¤.
* ì´ì— ë”°ë¼ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë…ë¦½ë³€ìˆ˜ì˜ ê°œìˆ˜ì— ë”°ë¼ ì¦ê°€í•˜ëŠ” ê²ƒì— ëŒ€í•œ íŒ¨ë„í‹°ë¥¼ ì ìš©ì‹œí‚¨ë‹¤.
  $AdjustedR^{2}=\displaystyle1-\dfrac{SSR\div(n-k-1)}{SST\div(n-1)}$
  > ğŸ’¡ nì´ ì»¤ì§„ë‹¤ë©´ 1, 2ë“¤ì˜ ê°’ì˜ ì°¨ì´ëŠ” í° ì˜ë¯¸ê°€ ì—†ì–´ ììœ ë„ë¡œ ë‚˜ëˆ„ì§€ ì•Šê³  nìœ¼ë¡œ ë‚˜ëˆˆë‹¤.
  > 
  >   sklearn.metiricsì— ìˆëŠ” mean_square_errorë„ nìœ¼ë¡œ ë‚˜ëˆˆ ê°’ì´ë‹¤.
  
### âš‘ íšŒê·€ë¶„ì„ ê²€í† ì‚¬í•­
1. ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì˜ ì í•©í•˜ê³  ìˆëŠ”ê°€?
   * ëª¨í˜•ì˜ ì”ì°¨(residual= $y_i-\hat{y}_i$)ê°€ íŠ¹ì • íŒ¨í„´ì„ ì´ë£¨ê³  ìˆì§€ ì•Šì•„ì•¼ í•œë‹¤.
   ![](https://cdn.teamturing.com/cms/1684451284_residual.png)
2. íšŒê·€ ëª¨í˜•ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œê°€?
   * ì„ í˜• íšŒê·€ ëª¨í˜•ì˜ í†µê³„ëŸ‰ì€ F í†µê³„ëŸ‰ì„ ì‚¬ìš©í•œë‹¤. F í†µê³„ëŸ‰ì˜ p-valueê°€ ìœ ì˜ìˆ˜ì¤€ë³´ë‹¤ ì‘ìœ¼ë©´ íšŒê·€ì‹ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì´ë•Œì˜ ê·€ë¬´ê°€ì„¤ê³¼ ëŒ€ë¦½ê°€ì„¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
     * ê·€ë¬´ê°€ì„¤(H0) : íšŒê·€ ëª¨í˜•ì€ ìœ ì˜í•˜ì§€ ì•Šë‹¤.
     * ëŒ€ë¦½ê°€ì„¤(H1) : íšŒê·€ ëª¨í˜•ì€ ìœ ì˜í•˜ë‹¤.
3. ëª¨í˜•ì€ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì„¤ëª…í•  ìˆ˜ ìˆëŠ”ê°€?
   * $R^{2}$ì˜ ê°’ì„ í™•ì¸í•œë‹¤. $R^{2}$ì€ ë¹„ìœ¨ì´ê¸°ì— 0~1ì˜ ê°’ì„ ê°€ì§€ë©°, ì¶”ì •ëœ íšŒê·€ì‹ì´ ì „ì²´ ë°ì´í„°ì—ì„œ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì˜ ë¹„ìœ¨ì´ë‹¤.
4. ëª¨í˜• ë‚´ì˜ íšŒê·€ê³„ìˆ˜ëŠ” ìœ ì˜í•œê°€?
   * íšŒê·€ê³„ìˆ˜ì— ëŒ€í•´ì„œëŠ” ê° ë…ë¦½ë³€ìˆ˜ë¥¼ ê²€ì •í•´ì•¼ í•œë‹¤.
   * íšŒê·€ê³„ìˆ˜ì— ëŒ€í•œ í†µê³„ëŸ‰ì€ tê°’ì´ë©°, p-valueê°€ ìœ ì˜ìˆ˜ì¤€ë³´ë‹¤ ì‘ìœ¼ë©´ íšŒê·€ê³„ìˆ˜ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.


### âš‘ ë‹¤ì¤‘ íšŒê·€ë¶„ì„ ì‹œ ìœ ì˜ì‚¬í•­
#### 1. ë‹¤ì¤‘ê³µì„ ì„±
* ë‹¤ì¤‘ê³µì„ ì„±ì´ë€ íšŒê·€ë¶„ì„ì—ì„œ ë…ë¦½ë³€ìˆ˜ë“¤ ê°„ ê°•í•œ ìƒê´€ê´€ê³„ê°€ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ì œë¥¼ ë§í•œë‹¤.
* ë‹¤ì¤‘ê³µì„ ì„±ì˜ ë¬¸ì œê°€ ì¡´ì¬í•˜ë©´ ì •í™•í•œ íšŒê·€ê³„ìˆ˜ ì¶”ì •ì´ ì–´ë µê³ , íšŒê·€ë¶„ì„ì—ì„œëŠ” ë…ë¦½ë³€ìˆ˜ì˜ ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ ëª¨ë¸ì˜ ì •í™•ë„ê°€ ì˜¬ë¼ê°€ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ë¯€ë¡œ ë‹¤ì¤‘ê³µì„ ì„ ì´ ì¡´ì¬í•œë‹¤ë©´ í•˜ë‚˜ì˜ ë³€ìˆ˜ë¥¼ ì œê±°í•´ì£¼ê±°ë‚˜ í•´ë‹¹ ë³€ìˆ˜ì— íŒ¨ë„í‹°ë¥¼ ì£¼ì–´ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì„ ì¤„ì—¬ì•¼ í•œë‹¤.
  * íŒ¨ë„í‹°ë¥¼ ì¤„ì´ëŠ” ë°©ë²•ì€ Ridge, Lasso íšŒê·€ë¶„ì„ì—ì„œ ë‹¤ë£¬ë‹¤.)
* ë‹¤ì¤‘ê³µì„ ì„±ì„ ê²€ì‚¬í•˜ê³  ì§„ë‹¨í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
  1. ë…ë¦½ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ êµ¬í•˜ì—¬ ìƒê´€ì„±ì„ ì§ì ‘ íŒŒì•…, ì ˆëŒ“ê°’ì´ 0.9 ì´ìƒì´ë¼ë©´ ë‹¤ì¤‘ê³µì„ ì„±ì´ ìˆë‹¤ê³  íŒë‹¨í•œë‹¤.
  2.  ë‹¤ì¤‘ê³µì„ ì„±ì´ ì˜ì‹¬ë˜ëŠ” ë‘ ë…ë¦½ë³€ìˆ˜ë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§„ íšŒê·€ë¶„ì„ìœ¼ë¡œ í—ˆìš© ì˜¤ì°¨ë¥¼ êµ¬í–ˆì„ ë•Œ, 0.1 ì´í•˜ì´ë©´ ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œê°€ ì‹¬ê°í•˜ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.
    > ğŸ’¡ í—ˆìš© ì˜¤ì°¨  $=1-R^2$
  3. VIF(variance inflation factor)ì˜ ê°’ì´ 10 ì´ìƒì´ë¼ë©´ ë‹¤ì¤‘ê³µì„ ì„±ì´ ì¡´ì¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒí•œë‹¤.
    > ğŸ’¡ $VIF = \dfrac{1}{1-R^2}$
* 2, 3ë²ˆ ë°©ë²•ì€ ê²°ì •ê³„ìˆ˜ì— ì˜í•´ ê²°ì •ë˜ëŠ”ë°, ë…ë¦½ë¼Œìˆ˜ì˜ ê°œìˆ˜ê°€ ë§ì•„ì§ˆ ìˆ˜ë¡ ê³„ì‚°ì˜ ì–‘ì€ ${}_{n}\mathrm{C}_{2}$ë¡œ ë§ì•„ì§„ë‹¤.
* VIFëŠ” íŒŒì´ì¬ì„ í†µí•´ êµ¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, VIFë¡œ ìµœëŒ€í•œ ì§„ë‹¨í•˜ê³  2, 3ë²ˆì„ ì´ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.

#### 2. ë³€ìˆ˜ì„ íƒë²•
* ë‹¤ì¤‘ê³µì„ ì„±ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš° í•˜ë‚˜ì˜ ë³€ìˆ˜ë¥¼ ì‚­ì œí•˜ê±°ë‚˜ íŒ¨ë„í‹°ë¥¼ ì£¼ì–´ í•´ê²°í•˜ëŠ”ë°, ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„ì—ì„œëŠ” ì´ ì™¸ì—ë„ ë³€ìˆ˜ë¥¼ ì œê±°í•´ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ìƒê¸´ë‹¤.
  * ëª¨í˜• ë‚´ ì„¤ëª…ë³€ìˆ˜ì˜ ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ ëª¨ë¸ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” ë° ë§ì€ ë¹„ìš©ê³¼ ë…¸ë ¥ì´ ìš”êµ¬ëœë‹¤.
* ë”°ë¼ì„œ ì¢…ì†ë³€ìˆ˜ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìœ ì˜ë¯¸í•œ ë…ë¦½ë³€ìˆ˜ë§Œì„ ì„ íƒí•˜ì—¬ ìµœì ì˜ íšŒê·€ë°©ì •ì‹ì„ ë„ì¶œí•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.
  * ë³€ìˆ˜ë¥¼ ì„ íƒí•  ë•Œì—ëŠ” ëª¨ë¸ì˜ ìœ ì˜ì„± íŒë‹¨ì˜ ê·¼ê±°ë¡œ ì‚¼ì•˜ë˜ Fí†µê³„ëŸ‰ì´ë‚˜ AICì™€ ê°™ì€ ê¸°ì¤€ê°’ì„ ê·¼ê±°ë¡œ ì œê±° ë˜ëŠ” ì„ íƒí•œë‹¤.
  > ğŸ’¡ $AIC = -2\ln(L)+2k$
  >
  > $2\ln(L)$ : ëª¨í˜•ì˜ ì í•©ë„
  >
  >   * ì´ì— ë”°ë¼ AICì˜ ê°’ì´ ë‚®ë‹¤ëŠ” ê²ƒì€ ëª¨í˜•ì˜ ì í•©ë„ê°€ ë†’ì€ ê²ƒì„ ì˜ë¯¸í•œë‹¤.
  >
  > $k$ = ì¶”ì •ëœ íŒŒë¼ë¯¸í„°ì˜ ê°œìˆ˜
  
  
* ë³€ìˆ˜ ì„ íƒë²•ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì´ 3ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤.

  |êµ¬ë¶„|ë‚´ìš©|
  |:--:|--|
  |ì „ì§„ì„ íƒë²•|ë‹¨ìˆœ ì„ í˜• íšŒê·€ë¶„ì„ì—ì„œ í•˜ë‚˜ì˜ ë³€ìˆ˜ì”© ì¶”ê°€í•´ê°€ë©° ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ë°©ë²•|
  |í›„ì§„ì œê±°ë²•|ëª¨ë“  ë³€ìˆ˜ë¥¼ ì¶”ê°€í•œ ìƒíƒœì—ì„œ ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ë“¤ì„ ì œê±°í•´ê°€ë©° ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°©ë²•|
  |ë‹¨ê³„ì  ì„ íƒë²•|ë³€ìˆ˜ë¥¼ ì¶”ê°€, ì œê±°í•˜ë©° ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë°©ë²•|
  
#### ğŸ§‘â€ğŸ’» ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„ ì‹¤ìŠµ

```python
# cars93 ë°ì´í„°ë¡œ í•´ë³´ê¸°
import pandas as pd

cars = pd.read_csv('./data/cars93.csv')
cars.drop(columns = 'Unnamed: 0', inplace=True)
cars.info()

# priceë¥¼ ì¢…ì†ë³€ìˆ˜, enginesize, rpm, weight, length, mpg.city, mpg.highwayë¥¼ ë…ë¦½ë³€ìˆ˜ë¡œ ë†“ê³  priceì— ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜ë¥¼ ì°¾ê¸° ìœ„í•œ íšŒê·€ë¶„ì„ í•´ë³´ê¸°
import statsmodels.api as sm
import statsmodels.formula.api as smf

# ols ëª¨ë¸ì˜ formulaë¥¼ ì •ì˜í•  ë•Œ, ì¼ë¶€ íŠ¹ìˆ˜ë¬¸ìëŠ” ì“¸ ìˆ˜ ì—†ê¸°ì— ë°ì´í„° ì „ì²˜ë¦¬
cars.columns = cars.columns.str.replace('.', '')
model = smf.ols(formula = 'Price ~ EngineSize + RPM + Weight + Length + MPGcity + MPGhighway', data = cars)
result = model.fit()
result.summary()
```
![](https://velog.velcdn.com/images/dmis/post/3b07d224-dd85-4b88-bf37-5614470295ed/image.png)

> ğŸ‘€ ** <span style="color:#7FFFD4;"> ìœ„ì˜ ìš”ì•½ ì •ë³´ì— ëŒ€í•œ í•´ì„</span>**
>
> * Adj.R-sqauredì˜ ê°’ì´ 0.542ë¡œ ë‚®ì€ ìˆ˜ì¹˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
>
> * 6ê°œì˜ ë³€ìˆ˜ë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ì˜€ì„ ë•Œ, Priceì˜ 54.2%ë§Œì„ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.
> 
> * ì´ì œ ë‹¤ì¤‘ê³µì„ ì„±ì„ í™•ì¸í•˜ê³ , ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì—¬ ë” ì¢‹ì€ íšŒê·€ì‹ì„ ì°¾ì•„ë³´ì.

```python
# ë‹¤ì¤‘ê³µì„ ì„± íŒŒì•…ì„ ìœ„í•´ ìƒê´€ê´€ê³„ íŒŒì•…í•˜ê¸°
cars_x = cars[['EngineSize', 'RPM', 'Weight', 'Length', 'MPGcity', 'MPGhighway']]
cars_x.corr()
```

![](https://velog.velcdn.com/images/dmis/post/b5258622-c8df-43d4-9936-9dbfa34a5e64/image.png)

> ğŸ‘€ ** <span style="color:#7FFFD4;">ìƒê´€ê³„ìˆ˜ë¡œ ì•Œ ìˆ˜ ìˆëŠ” ì‚¬ì‹¤</span>**
>
> * MPGcityì™€ MPGhighwayëŠ” 0.9 ì´ìƒì˜ ìƒê´€ì„±ì„ ë³´ì´ë¯€ë¡œ ë‹¤ì¤‘ê³µì„ ì„±ì´ ì¡´ì¬í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.
>
> * í•˜ì§€ë§Œ ë‘˜ ì¤‘ ì–´ë– í•œ ë³€ìˆ˜ë¥¼ ì œê±°í•´ì•¼ í•˜ëŠ”ì§€ëŠ” ê²°ì •í•˜ê¸° ì• ë§¤í•˜ë‹¤.
>
> * ì´ë•Œ, ë‹¤ìŒê³¼ ê°™ì´ VIFë¥¼ êµ¬í•˜ì—¬ ê²°ì •í•  ìˆ˜ ìˆë‹¤.


```python
from patsy import dmatrices
from statsmodels.stats.outliers_influence import variance_inflation_factor
# dmatrices : ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
y, x = dmatrices('Price ~ EngineSize + RPM + Weight + Length + MPGcity + MPGhighway', data = cars, return_type = 'dataframe')

# ë…ë¦½ë³€ìˆ˜ë¼ë¦¬ì˜ VIF ê°’ì„ ê³„ì‚°í•˜ì—¬ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸°
vif_list = []
for i in range(1, len(x.columns)):
    vif_list.append([variance_inflation_factor(x.values, i), x.columns[i]])
vif_df = pd.DataFrame(vif_list, columns = ['vif', 'variable'])
vif_df
```

![](https://velog.velcdn.com/images/dmis/post/86400191-6963-4073-be71-1954390c0c92/image.png)

> ğŸ‘€ ** <span style="color:#7FFFD4;">VIFë¥¼ í†µí•´ ì•Œ ìˆ˜ ìˆëŠ” ì‚¬ì‹¤</span>**
> 
> * MPGcityì˜ VIFê°€ MPGhighwayì˜ VIFë³´ë‹¤ í¬ë¯€ë¡œ MPGcityë¥¼ ì œê±°í•´ì•¼í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.

```python
# MPGcityë¥¼ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¶„ì„ ì§„í–‰í•´ë³´ê¸°
model = smf.ols(formula= 'Price ~ EngineSize + RPM + Weight + Length +  MPGhighway', data = cars)
result = model.fit()
result.summary()
```

> ğŸ‘€ **<span style="color:#7FFFD4;">ì•Œ ìˆ˜ ìˆëŠ” ì‚¬ì‹¤</span>**
> 
> * ì•ì„œ ë¶„ì„í–ˆë˜ ëª¨ë¸ë³´ë‹¤ $Adj.R^2$ê³¼ AICì˜ í° ë³€í™”ëŠ” ì—†ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.
>
> * ë‹¤ì¤‘ê³µì„ ì„±ì˜ ì œê±°ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥í–¥ìƒë³´ë‹¤ëŠ” ë¬´ë¶„ë³„í•œ ë³€ìˆ˜ ì„ íƒìœ¼ë¡œ ë°ì´í„°ì˜ ê´€ë¦¬ê°€ ì–´ë ¤ì›Œì§€ëŠ” í˜„ìƒì„ ë§‰ëŠ” ê²ƒì— ì˜ì˜ê°€ ìˆë‹¤.
> 
> * MPGcityë¥¼ ì œê±°í•˜ì MPGhighwayì˜ p-valueê°€ í˜„ì €íˆ ë‚®ì•„ì§„ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.
> 
>   * ì´ì²˜ëŸ¼ ìœ ì˜í•œ ë³€ìˆ˜ì„ì—ë„ ë‹¤ì¤‘ê³µì„ ì„±ì˜ ì´ìœ ë¡œ ìœ ì˜í•˜ì§€ ì•Šì€ ë³€ìˆ˜ì²˜ëŸ¼ ì—¬ê²¨ì§ˆ ìˆ˜ ìˆë‹¤.
> 
>     * ë”°ë¼ì„œ ë‹¤ì¤‘ê³µì„ ì„±ì€ ê¼­ í•´ê²°í•´ì•¼í•  ê³¼ì œì´ë‹¤.

```python
# ì½”ë“œ í™•ì¸ í•„ìš”
# ë…ë¦½ë³€ìˆ˜ ì¤‘ ìœ ì˜í•œ ë³€ìˆ˜ë¥¼ ê³ ë¥´ê³ , ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ìµœì í™”ì‹œí‚¤ëŠ” ë³€ìˆ˜ ì„ íƒë²• ì§„í–‰í•´ë³´ê¸°

import time
import itertools

def processSubset(x, y, feature_set) :
    model = sm.OLS(y, x[list(feature_set)]) # modeling
    regr = model.fit() # ëª¨ë¸ í•™ìŠµ
    AIC = regr.aic
    return {"model":regr, "AIC":AIC}

# ì „ì§„ì„ íƒë²•
def forward (x, y, predictors) :
    # ë°ì´í„° ë³€ìˆ˜ë“¤ì´ ë¯¸ë¦¬ ì •ì˜ëœ predictoresì— ìˆëŠ”ì§€ ì—†ëŠ”ì§€ í™•ì¸ ë° ë¶„ë¥˜
    remaining_predictors = [p for p in x.columns.difference(['Intercept'])
                            if p not in predictors]
    results = []
    for p in remaining_predictors :
        results.append(processSubset(x=x, y=y, feature_set=predictors+[p]+['Intercept']))

    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    models = pd.DataFrame(results)
    print(models)
    # AICê°€ ê°€ì¥ ë‚®ì€ ê²ƒì„ ì„ íƒ
    best_model = models.loc[models['AIC'].argmin()] # index
    print('Processed', models.shape[0], 'models on', len(predictors)+1, 'predictors in')
    print('Selected predictors:', best_model['model'].model.exog_names, 'AIC:', best_model[0])

    return best_model

# =====

# í›„ì§„ì œê±°ë²•
def backward(x, y, predictors) :
    tic = time.time()
    results = []

    # ë°ì´í„° ë³€ìˆ˜ë“¤ì´ ë¯¸ë¦¬ ì •ì˜ëœ predictors ì¡°í•© í™•ì¸
    for combo in itertools.combinations(predictors, len(predictors)+1):
        results.append(processSubset(x=x, y=y, feature_set= list(combo)+['Intercept']))
    models = pd.DataFrame(results)

    # ê°€ì¥ ë‚®ì€ AICë¥¼ ê°€ì§„ ëª¨ë¸ì„ ì„ íƒ
    best_model = models.loc[models['AIC'].argmin()] # index
    toc = time.time()

    print('Processed', models.shape[0], 'models on', len(predictors)+1, 'predictors in', (toc - tic))
    print('Selected predictors:', best_model['model'].model.exog_names, 'AIC:', best_model[0])

    return best_model

# =====

# ë‹¨ê³„ì  ì„ íƒë²•
def Stepwise_model(x, y) :
    Stepmodels = pd.DataFrame(columns = ['AIC', 'model'])
    tic = time.time()
    predictors = []
    Smodel_before = processSubset(x, y, predictors+['Intercept'])['AIC']

    for i in range(1, len(x.columns.difference(['Intercept']))+1) :
        forward_result = forward(x=x, y=y, predictors = predictors)
        print('forward')
        Stepmodels.loc[i] = forward_result
        Stepmodels = Stepmodels.loc[i]['model'].model.exog_names
        predictors = [k for k in predictors if k!='Intercept']
        backward_result = backward(x=x, y=y, predictors = predictors)

        if backward_result['AIC'] < forward_result['AIC'] :
            Stepmodels.loc[i] = backward_result
            predictors = Stepmodels.loc[i]['model'].model.exog_names
            Smodel_before = Stepmodels.loc[i]['AIC']
            predictors = [k for k in predictors if k!='Intercept']
            print('backward')

        if Stepmodels.loc[i]['AIC'] > Smodel_before:
            break
        else :
            Smodel_before = Stepmodels.loc[i]['AIC']
    toc = time.time()
    print('Total elapsed time:',(toc-tic), 'seconds.')

    return (Stepmodels['model'][len(Stepmodels['model'])])

Stepwise_best_model = Stepwise_model(x=x, y=y)
```